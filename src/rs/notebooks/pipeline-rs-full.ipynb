{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipeline - full recordings, resting state data\n",
    "\n",
    "This notebook acts as the finalized pipeline for processing the full recordings of resting-state data, and computes PSDs, slopes, and outputs a samples-features matrix for statistical analysis. The analysis covers both eyes-closed and eyes-open data. Data has been preprocessed in MATLAB using the parameters and functions specified at `../data/pipeline-full/pipeline.txt`\n",
    "\n",
    "The notebook is divided into the following sections:\n",
    "0. **Parameters:** Parameter selection for running the analysis.\n",
    "1. **PSD Calculations:** Loading subject PSDs for both older and younger adults.\n",
    "2. **Fit to PSD Slopes:** Fitting to specified frequency range with specified fitting method (either simple linear regression or RANSAC).\n",
    "3. **Construct Samples-Features Matrix:** Exporting results to a samples-features matrix, for statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import numpy.fft\n",
    "import scipy.signal\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress, ttest_ind\n",
    "from sklearn import linear_model\n",
    "mpl.rcParams['figure.figsize'] = (16, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "- `recompute_psds`: `True` or `False`, for recomputing subject PSDs or loading previous results.\n",
    "- `psd_buffer_lofreq`: Scalar, specifies the lower bound for the PSD buffer that we exclude.\n",
    "- `psd_buffer_hifreq`: Scalar, specifies the upper bound for the PSD buffer that we exclude.\n",
    "- `fitting_func`: `'linreg'` or `'ransac'`, specifies which function to use for fitting. `'linreg'` is simple linear regression. `'ransac'` is RANSAC, a robust fitting method that ignores outliers.\n",
    "- `fitting_lofreq`: Scalar, specifies the lower bound for the PSD fitting range.\n",
    "- `fitting_hifreq`: Scalar, specifies the upper bound for the PSD fitting range.\n",
    "- `import_dir`: String specifying the directory to import results to.\n",
    "- `export_dir`: String specifying the directory to export results to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recompute_psds = True\n",
    "psd_buffer_lofreq = 7\n",
    "psd_buffer_hifreq = 14\n",
    "fitting_func = 'ransac'\n",
    "fitting_lofreq = 2\n",
    "fitting_hifreq = 24\n",
    "import_dir = '/Users/jorge/Drive/research/_psd-slope/data/rs-full/ExclFiltCARClust-mat/'\n",
    "export_dir = '/Users/jorge/Drive/research/_psd-slope/data/rs-full/results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set up workspace, print out parameters to text file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_time = '-'.join('_'.join(str(datetime.datetime.now()).split()).split(':'))[:-7]\n",
    "export_dir = export_dir + current_time + '/'\n",
    "os.mkdir(export_dir)\n",
    "params = open(export_dir + 'parameters.txt', 'w')\n",
    "params.write('recompute_psds = ' + str(recompute_psds))\n",
    "params.write('\\npsd_buffer_lofreq = ' + str(psd_buffer_lofreq))\n",
    "params.write('\\npsd_buffer_hifreq = ' + str(psd_buffer_hifreq))\n",
    "params.write('\\nfitting_func = ' + str(fitting_func))\n",
    "params.write('\\nfitting_lofreq = ' + str(fitting_lofreq))\n",
    "params.write('\\nfitting_hifreq = ' + str(fitting_hifreq))\n",
    "params.write('\\nimport_dir = ' + str(import_dir))\n",
    "params.write('\\nexport_dir = ' + str(export_dir))\n",
    "params.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject Importing & PSD Calculations\n",
    "\n",
    "This section imports subject information and computes PSDs using Welch's method. The algorithm proceeds as follows, for each channel:\n",
    "1. Extract as many clean 2-second eyes closed and eyes open segments from the recording. Segments overlap by 50%.\n",
    "2. Multiply each 2-second segment by a 2-second Hamming window. \n",
    "3. Compute the discrete Fourier transform of each segment, and average DFT'd segments to arrive at a per-channel PSD.\n",
    "\n",
    "The PSD is defined as:\n",
    "$$\n",
    "PSD = log_{10}(\\sum\\limits_{n=1}^{N}{N})\n",
    "$$\n",
    "\n",
    "##### Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_filelist(import_path):\n",
    "    matfiles = []\n",
    "    for root, dirs, files in os.walk(import_path):\n",
    "        matfiles += glob.glob(os.path.join(root, '*.mat'))\n",
    "    return matfiles\n",
    "\n",
    "def import_subject(subj, i, import_path):\n",
    "    \"\"\" \n",
    "    Imports a single subject and adds them to the subj\n",
    "    data structure. Additionally, merges \n",
    "    \"\"\"\n",
    "    subj[i] = {}\n",
    "    datafile = sp.io.loadmat(import_path)\n",
    "    subj[i]['name'] = str(np.squeeze(datafile['name']))\n",
    "    subj[i]['srate'] = int(np.squeeze(datafile['srate']))\n",
    "    subj[i]['events'] = []\n",
    "    for event in np.squeeze(datafile['evts']):\n",
    "        subj[i]['events'].append([event[0][0], event[1][0][0], event[2][0][0]])\n",
    "    subj[i]['data'] = np.squeeze(datafile['data'])\n",
    "    subj[i]['nbchan'] = len(subj[i]['data'])\n",
    "    return subj\n",
    "\n",
    "def _print_window_info(events, port_code):\n",
    "    evts = [[events[i][1], events[i+1][1]] for i in range(len(events)) if events[i][0] == port_code]\n",
    "    total_wins = 0\n",
    "    total_secs = 0\n",
    "    for e in evts:\n",
    "        if (e[1] - e[0]) >= 1024:\n",
    "            pts  = e[1] - e[0]\n",
    "            secs = (e[1] - e[0])//512\n",
    "            nwin = (e[1] - e[0])//512 - 1\n",
    "            total_wins += nwin\n",
    "            total_secs += secs\n",
    "            print('Event {}:\\t{} points, {} seconds, {} windows'.format(e, pts, secs, nwin))\n",
    "    print('Total windows able to be extracted: ', total_wins)\n",
    "\n",
    "def get_windows(data, events, port_code, nperwindow=512*2, noverlap=512):\n",
    "    windows = []\n",
    "    # The following line restructures events of type port_code into the \n",
    "    # following format:\n",
    "    #         [start_time, end_time]\n",
    "    evts = [[events[i][1], events[i+1][1]] for i in range(len(events)) if events[i][0] == port_code]\n",
    "    for event in evts:\n",
    "        if event[1]-event[0] >= nperwindow:\n",
    "            nwindows = (event[1] - event[0])//noverlap - 1\n",
    "            for i in range(nwindows):\n",
    "                windows.append(data[event[0] + noverlap*i : event[0] + noverlap*i + nperwindow])\n",
    "    return windows\n",
    "\n",
    "def welch(windows, srate):\n",
    "    \"\"\"\n",
    "    Takes a list of data segments (each size 1xN), computes each segment's PSD,\n",
    "    and averages them to get a final PSD.\n",
    "    \"\"\"\n",
    "    psds = [sp.signal.welch(window, srate, nperseg=len(window), window='hamming')[1] for window in windows]\n",
    "    return np.mean(psds, axis=0)\n",
    "\n",
    "def remove_freq_buffer(data, lofreq, hifreq):\n",
    "    \"\"\"\n",
    "    Removes a frequency buffer from a PSD or frequency vector.\n",
    "    \"\"\"\n",
    "    data = np.delete(data, range(lofreq*2, hifreq*2))\n",
    "    return data.reshape(len(data), 1)\n",
    "\n",
    "def compute_subject_psds(import_path, import_path_csv):\n",
    "    \"\"\" Returns subj data structure with calculated PSDs and subject information.\n",
    "    Arguments:\n",
    "        import_path:     String, path to .mat files\n",
    "        import_path_csv: String, path to .csv containing subject class, sex, and\n",
    "                         age information. \n",
    "    \"\"\"\n",
    "    matfiles = get_filelist(import_path)\n",
    "    df = pd.read_csv(import_path_csv)\n",
    "    df.SUBJECT = df.SUBJECT.astype(str)\n",
    "\n",
    "    subj = {}\n",
    "    subj['nbsubj'] = len(matfiles)\n",
    "    subj['f'] = np.linspace(0, 256, 513)\n",
    "    subj['f'] = subj['f'].reshape(len(subj['f']), 1)\n",
    "    subj['f_rm_alpha'] = remove_freq_buffer(subj['f'], 7, 14)\n",
    "    for i in range(len(matfiles)):\n",
    "        print(\"Processing: {}... \".format(matfiles[i].split('/')[-1]), end='')\n",
    "        \n",
    "        subj = import_subject(subj, i, matfiles[i])\n",
    "        subj[i]['age']   = df[df.SUBJECT == subj[i]['name']].AGE.values[0]\n",
    "        subj[i]['class'] = df[df.SUBJECT == subj[i]['name']].CLASS.values[0]\n",
    "        subj[i]['sex']   = df[df.SUBJECT == subj[i]['name']].SEX.values[0]\n",
    "\n",
    "        for ch in range(subj[i]['nbchan']):\n",
    "            subj[i][ch] = {}\n",
    "            eyesC_windows = get_windows(subj[i]['data'][ch], subj[i]['events'], 'C1')\n",
    "            eyesO_windows = get_windows(subj[i]['data'][ch], subj[i]['events'], 'O1')\n",
    "            subj[i][ch]['eyesC_psd'] = welch(eyesC_windows, 512)\n",
    "            subj[i][ch]['eyesO_psd'] = welch(eyesO_windows, 512)\n",
    "            subj[i][ch]['eyesC_psd_rm_alpha'] = remove_freq_buffer(subj[i][ch]['eyesC_psd'], 7, 14)\n",
    "            subj[i][ch]['eyesO_psd_rm_alpha'] = remove_freq_buffer(subj[i][ch]['eyesO_psd'], 7, 14)\n",
    "        subj[i]['data'] = np.nan # No longer needed, so clear it from memory\n",
    "        subj[i]['eyesC_psd'] = np.mean([subj[i][ch]['eyesC_psd'] for ch in range(subj[i]['nbchan'])], axis=0)\n",
    "        subj[i]['eyesO_psd'] = np.mean([subj[i][ch]['eyesO_psd'] for ch in range(subj[i]['nbchan'])], axis=0)\n",
    "        subj[i]['eyesC_psd_rm_alpha'] = remove_freq_buffer(subj[i]['eyesC_psd'], 7, 14)\n",
    "        subj[i]['eyesO_psd_rm_alpha'] = remove_freq_buffer(subj[i]['eyesO_psd'], 7, 14)\n",
    "        print(\"Done.\")\n",
    "    return subj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 1121181181.mat... Done.\n",
      "Processing: 1121181183.mat... Done.\n",
      "Processing: 1121181218.mat... Done.\n",
      "Processing: 1121181262.mat... Done.\n",
      "Processing: 1121181286.mat... Done.\n",
      "Processing: 112118131.mat... Done.\n",
      "Processing: 1121181334.mat... Done.\n",
      "Processing: 112118135.mat... Done.\n",
      "Processing: 1121181393.mat... Done.\n",
      "Processing: 1121181418.mat... Done.\n",
      "Processing: 1121181424.mat... Done.\n",
      "Processing: 1121181428.mat... Done.\n",
      "Processing: 1121181510.mat... Done.\n",
      "Processing: 1121181517.mat... Done.\n",
      "Processing: 1121181575.mat... Done.\n",
      "Processing: 112118167.mat... Done.\n",
      "Processing: 112118204.mat... Done.\n",
      "Processing: 112118257.mat... Done.\n",
      "Processing: 112118266.mat... Done.\n",
      "Processing: 112118334.mat... Done.\n",
      "Processing: 112118373.mat... Done.\n",
      "Processing: 112118416.mat... Done.\n",
      "Processing: 112118463.mat... Done.\n",
      "Processing: 112118468.mat... Done.\n",
      "Processing: 112118475.mat... Done.\n",
      "Processing: 112118479.mat... Done.\n",
      "Processing: 112118521.mat... Done.\n",
      "Processing: 112118526.mat... Done.\n",
      "Processing: 112118576.mat... Done.\n",
      "Processing: 112118578.mat... Done.\n",
      "Processing: 112118587.mat... Done.\n",
      "Processing: 112118642.mat... Done.\n",
      "Processing: 112118723.mat... Done.\n",
      "Processing: 112118761.mat... Done.\n",
      "Processing: 112118762.mat... Done.\n",
      "Processing: 112118785.mat... Done.\n",
      "Processing: 120127101.mat... Done.\n",
      "Processing: 120127102.mat... Done.\n",
      "Processing: 120127103.mat... Done.\n",
      "Processing: 120127104.mat... Done.\n",
      "Processing: 120127105.mat... Done.\n",
      "Processing: 120127106.mat... Done.\n",
      "Processing: 120127107.mat... Done.\n",
      "Processing: 120127108.mat... Done.\n",
      "Processing: 120127109.mat... Done.\n",
      "Processing: 120127110.mat... Done.\n",
      "Processing: 120127111.mat... Done.\n",
      "Processing: 120127112.mat... Done.\n",
      "Processing: 120127113.mat... Done.\n",
      "Processing: 120127114.mat... Done.\n",
      "Processing: 120127115.mat... Done.\n",
      "Processing: 120127116.mat... Done.\n",
      "Processing: 120127117.mat... Done.\n",
      "Processing: 120127118.mat... Done.\n",
      "Processing: 120127119.mat... Done.\n",
      "Processing: 120127120.mat... Done.\n",
      "Processing: 120127121.mat... Done.\n",
      "Processing: 120127122.mat... Done.\n",
      "Processing: 120127123.mat... Done.\n",
      "Processing: 120127124.mat... Done.\n",
      "Processing: 120127125.mat... Done.\n",
      "Processing: 120127128.mat... Done.\n",
      "Processing: 120127130.mat... Done.\n",
      "Processing: 120127131.mat... Done.\n",
      "Processing: 120127132.mat... Done.\n",
      "Processing: 120127134.mat... Done.\n",
      "Processing: 120127135.mat... Done.\n",
      "Processing: 120127137.mat... Done.\n",
      "Processing: 120127138.mat... Done.\n",
      "Processing: 120127139.mat... Done.\n",
      "Processing: 120127140.mat... Done.\n",
      "Processing: 120127142.mat... Done.\n",
      "Processing: 120127144.mat... Done.\n",
      "Processing: 120127145.mat... Done.\n",
      "Processing: 120127146.mat... Done.\n",
      "Processing: 120127147.mat... Done.\n",
      "Processing: 120127148.mat... Done.\n",
      "Processing: 120127149.mat... Done.\n",
      "Processing: 120127151.mat... Done.\n",
      "Processing: 120127153.mat... Done.\n",
      "Processing: 120127154.mat... Done.\n",
      "Processing: 120127155.mat... Done.\n",
      "Processing: 120127156.mat... Done.\n",
      "Processing: 120127157.mat... Done.\n",
      "Processing: 120127158.mat... Done.\n",
      "Processing: 120127159.mat... Done.\n",
      "Processing: 120127160.mat... Done.\n",
      "Processing: 120127161.mat... Done.\n",
      "Processing: 120127162.mat... Done.\n",
      "Processing: 120127163.mat... Done.\n",
      "Processing: 120127164.mat... Done.\n",
      "Processing: 120127165.mat... Done.\n",
      "Processing: 120127166.mat... Done.\n",
      "Processing: 120127167.mat... Done.\n",
      "Processing: 120127168.mat... Done.\n",
      "Processing: 120127169.mat... Done.\n",
      "Processing: 120127170.mat... Done.\n"
     ]
    }
   ],
   "source": [
    "if recompute_psds:\n",
    "    # Import EEG for older and younger adults, compute PSDs\n",
    "    subj = compute_subject_psds(import_dir, '../../data/ya-oa.csv')\n",
    "\n",
    "    # Save resulting PSDs\n",
    "    subj['time_computed'] = current_time\n",
    "    np.save(export_dir + '/subj-no-fitting.npy', subj); subj = []\n",
    "else:\n",
    "    # Use files with pre-computed PSDs and a 7 - 14 Hz buffer\n",
    "    !cp /Users/jorge/Dropbox/research/_psd-slope/data/rs-full/subj-no-fitting.npy $export_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit to Spectral Slopes\n",
    "\n",
    "Now we compute PSD slopes for each channel of each subject, and additionally calculate each subject's mean PSD slope. This is found by fitting to the grand average PSD of each subject.\n",
    "\n",
    "##### Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linreg_slope(f, psd, lofreq, hifreq):\n",
    "    \"\"\"\n",
    "    Fits line to the PSD, using simple linear regression.\n",
    "    Returns slope and fit line.\n",
    "    \"\"\"\n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(f[lofreq*2:hifreq*2], np.log10(psd[lofreq*2:hifreq*2]))\n",
    "    fit_line = model.predict(f)\n",
    "    return model.coef_[0] * (10**2), fit_line\n",
    "\n",
    "def ransac_slope(f, psd, lofreq, hifreq):\n",
    "    \"\"\"\n",
    "    Robustly fits line to the PSD, using the RANSAC algorithm. \n",
    "    Returns slope and fit line.\n",
    "    \"\"\"\n",
    "    model_ransac = linear_model.RANSACRegressor(linear_model.LinearRegression())\n",
    "    model_ransac.fit(f[lofreq*2:hifreq*2], np.log10(psd[lofreq*2:hifreq*2]))\n",
    "    fit_line = model_ransac.predict(f)\n",
    "    return model_ransac.estimator_.coef_[0] * (10**2), fit_line\n",
    "\n",
    "def fit_slopes(subj, regr_func, lofreq, hifreq):\n",
    "    \"\"\" \n",
    "    Takes subj data structure and fits slopes to each subject's PSDs and mean\n",
    "    PSD, using regr_func and fitting to datapoints between lofreq and hifreq.\n",
    "    \"\"\"\n",
    "    for i in range(subj['nbsubj']):\n",
    "        # Per-subject PSD average fitting\n",
    "        subj[i]['eyesC_slope'], subj[i]['eyesC_fitline'] = regr_func(subj['f'], subj[i]['eyesC_psd'], lofreq, hifreq)\n",
    "        subj[i]['eyesO_slope'], subj[i]['eyesO_fitline'] = regr_func(subj['f'], subj[i]['eyesO_psd'], lofreq, hifreq)\n",
    "        for ch in range(subj[i]['nbchan']):\n",
    "            # Per-channel PSD fitting\n",
    "            subj[i][ch]['eyesC_slope'], subj[i][ch]['eyesC_fitline'] = regr_func(subj['f'], subj[i][ch]['eyesC_psd_rm_alpha'], lofreq, hifreq)\n",
    "            subj[i][ch]['eyesO_slope'], subj[i][ch]['eyesO_fitline'] = regr_func(subj['f'], subj[i][ch]['eyesO_psd_rm_alpha'], lofreq, hifreq)\n",
    "    return subj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorge/Development/anaconda3/lib/python3.5/site-packages/scipy/linalg/basic.py:884: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Select fitting function\n",
    "if fitting_func == 'linreg':\n",
    "    regr = linreg_slope\n",
    "elif fitting_func == 'ransac':\n",
    "    regr = ransac_slope\n",
    "\n",
    "#Load subject PSDs\n",
    "if recompute_psds:\n",
    "    subj = np.load(export_dir + '/subj-no-fitting.npy').item()\n",
    "else:\n",
    "    subj = np.load('../../data/rs-full/subj-no-fitting.npy').item()\n",
    "    \n",
    "# Fit lines to slopes using specified function and frequency range\n",
    "subj = fit_slopes(subj, regr, fitting_lofreq, fitting_hifreq)\n",
    "\n",
    "# Save results\n",
    "filename = export_dir + 'subj-' + str(fitting_lofreq) + '-' + str(fitting_hifreq) + '-' + fitting_func + '.npy'\n",
    "subj['time_computed'] = current_time\n",
    "np.save(filename, subj); subj = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Samples-Features Matrix\n",
    "\n",
    "Now we construct the samples-features matrix containing the calculated slopes. We use a table that already contains subject numbers, sex, age, and memory class to start off.\n",
    "\n",
    "##### Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_subject_slopes(subj, ch, slope_type):\n",
    "    \"\"\" Returns list of slopes for specified channel of slope_type.\n",
    "    Arguments:\n",
    "        subj: The subj data structure.\n",
    "        ch:   Scalar, channel for which to get list of subject slopes.\n",
    "        slope_type: String, e.g., 'eyesO_slope' or 'eyesC_slope'\n",
    "    \"\"\"\n",
    "    if ch == -1: # Slope of PSD grand average\n",
    "        return [subj[i][slope_type]     for i in range(subj['nbsubj'])]\n",
    "    else:\n",
    "        return [subj[i][ch][slope_type][0] for i in range(subj['nbsubj'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving fitted slopes at:\n",
      " /Users/jorge/Drive/research/_psd-slope/data/rs-full/results/2016-11-15_15-19-23/ya-oa-full-ransac-2-24-eyesc-eyeso.csv\n"
     ]
    }
   ],
   "source": [
    "# Define channels, these will form labels for our table:\n",
    "channels = [\"A01\",\"A02\",\"A03\",\"A04\",\"A05\",\"A06\",\"A07\",\"A08\",\"A09\",\"A10\",\"A11\",\"A12\",\"A13\",\"A14\",\"A15\",\"A16\",\"A17\",\"A18\",\"A19\",\"A20\",\"A21\",\"A22\",\"A23\",\"A24\",\"A25\",\"A26\",\"A27\",\"A28\",\"A29\",\"A30\",\"A31\",\"A32\",\"B01\",\"B02\",\"B03\",\"B04\",\"B05\",\"B06\",\"B07\",\"B08\",\"B09\",\"B10\",\"B11\",\"B12\",\"B13\",\"B14\",\"B15\",\"B16\",\"B17\",\"B18\",\"B19\",\"B20\",\"B21\",\"B22\",\"B23\",\"B24\",\"B25\",\"B26\",\"B27\",\"B28\",\"B29\",\"B30\",\"B31\",\"B32\",\"FRONTAL\",\"LTEMPORAL\",\"CENTRAL\",\"RTEMPORAL\",\"OCCIPITAL\"]\n",
    "# Load subject PSDs with fitted slopes\n",
    "subj = np.load(filename).item()\n",
    "\n",
    "data = {}\n",
    "data['SUBJECT'] = [subj[i]['name'] for i in range(subj['nbsubj'])]\n",
    "data['CLASS']   = [subj[i]['class'] for i in range(subj['nbsubj'])]\n",
    "data['AGE']     = [subj[i]['age'] for i in range(subj['nbsubj'])]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df[['SUBJECT', 'CLASS', 'AGE']]\n",
    "\n",
    "# Add each subject's mean slope.\n",
    "df['AVG_PSD_EYESC'] = get_subject_slopes(subj, -1, 'eyesC_slope')\n",
    "df['AVG_PSD_EYESO'] = get_subject_slopes(subj, -1, 'eyesO_slope')\n",
    "\n",
    "# Now add slopes for every channel from each subject.\n",
    "for ch in range(len(channels)):\n",
    "    df[channels[ch] + '_EYESC'] = get_subject_slopes(subj, ch, 'eyesC_slope')\n",
    "for ch in range(len(channels)):\n",
    "    df[channels[ch] + '_EYESO'] = get_subject_slopes(subj, ch, 'eyesO_slope')\n",
    "\n",
    "# Export results\n",
    "filename = export_dir + 'ya-oa-full-' + fitting_func + '-' + str(fitting_lofreq) + '-' + str(fitting_hifreq) + '-eyesc-eyeso.csv'\n",
    "print('Saving fitted slopes at:\\n', filename)\n",
    "df.to_csv(filename, index=False); df = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Compute t-tests, logit, lasso\n",
    "\n",
    "And run t-tests, as well as LASSO in order to see if there are any group differences. \n",
    "\n",
    "### T-Tests\n",
    "\n",
    "##### Younger adults vs older adults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A28_EYESC:\t\t\t-2.53,\t0.014\n",
      "A32_EYESC:\t\t\t-2.82,\t0.007\n",
      "B17_EYESC:\t\t\t-2.01,\t0.049\n",
      "B25_EYESC:\t\t\t-2.25,\t0.029\n",
      "B28_EYESC:\t\t\t2.01,\t0.049\n",
      "B31_EYESC:\t\t\t-2.09,\t0.041\n",
      "B32_EYESC:\t\t\t-2.42,\t0.019\n",
      "A28_EYESO:\t\t\t-2.02,\t0.048\n",
      "A32_EYESO:\t\t\t-2.08,\t0.042\n",
      "B25_EYESO:\t\t\t-2.01,\t0.049\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(filename)\n",
    "ya = df[df.CLASS.isin(['DANE'])]\n",
    "oa = df[df.CLASS.isin(['SA_Control', 'MCI_Control'])]\n",
    "\n",
    "channels = list(df.columns.values)[4:]\n",
    "for ch in channels:\n",
    "    result = ttest_ind(ya[ch], oa[ch], equal_var=False)\n",
    "    if result[1] < 0.05:\n",
    "        print(\"{}:\\t\\t\\t{:.2f},\\t{:.3f}\".format(ch, result.statistic, result.pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Older adult controls vs SAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B12_EYESC:\t\t\t-2.11,\t0.047\n",
      "B24_EYESC:\t\t\t-2.04,\t0.050\n",
      "B27_EYESC:\t\t\t-2.25,\t0.034\n",
      "A05_EYESO:\t\t\t-2.14,\t0.039\n",
      "A07_EYESO:\t\t\t-2.07,\t0.047\n",
      "A13_EYESO:\t\t\t-2.71,\t0.011\n",
      "A15_EYESO:\t\t\t-2.22,\t0.035\n",
      "A19_EYESO:\t\t\t-2.14,\t0.039\n",
      "B01_EYESO:\t\t\t-2.13,\t0.042\n",
      "B02_EYESO:\t\t\t-2.96,\t0.006\n",
      "B03_EYESO:\t\t\t-3.03,\t0.004\n",
      "B05_EYESO:\t\t\t-2.45,\t0.020\n",
      "B06_EYESO:\t\t\t-3.20,\t0.003\n",
      "B20_EYESO:\t\t\t-2.31,\t0.029\n",
      "B22_EYESO:\t\t\t-2.16,\t0.037\n",
      "B23_EYESO:\t\t\t-2.57,\t0.015\n",
      "B24_EYESO:\t\t\t-2.22,\t0.032\n",
      "B27_EYESO:\t\t\t-2.43,\t0.023\n",
      "B29_EYESO:\t\t\t-2.28,\t0.029\n",
      "FRONTAL_EYESO:\t\t\t-2.73,\t0.009\n",
      "CENTRAL_EYESO:\t\t\t-2.29,\t0.030\n",
      "RTEMPORAL_EYESO:\t\t\t-2.24,\t0.031\n",
      "OCCIPITAL_EYESO:\t\t\t-2.05,\t0.048\n"
     ]
    }
   ],
   "source": [
    "oa_control = df[df.CLASS.isin(['SA_Control', 'MCI_Control'])]\n",
    "sa         = df[df.CLASS.isin(['SA'])]\n",
    "\n",
    "for ch in channels:\n",
    "    result = ttest_ind(oa_control[ch], sa[ch], equal_var=False)\n",
    "    if result[1] < 0.05:\n",
    "        print(\"{}:\\t\\t\\t{:.2f},\\t{:.3f}\".format(ch, result.statistic, result.pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression, younger adults vs older adult controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorge/Development/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "df_logit = df[df.CLASS.isin(['DANE', 'SA_Control', 'MCI_Control'])]\n",
    "\n",
    "df_logit['CLASS'] = list(map(lambda x: 0 if x == 'DANE' else 1, df_logit['CLASS']))\n",
    "\n",
    "cols = list(df_logit.columns.values)\n",
    "cols.remove('SUBJECT')\n",
    "cols.remove('CLASS')\n",
    "cols.remove('AGE')\n",
    "\n",
    "X = df_logit[cols]\n",
    "y = df_logit.CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by score, using 2000 resamplings: \n",
      "A32_EYESC:\t\t\t0.26\n",
      "A28_EYESC:\t\t\t0.11\n",
      "B32_EYESC:\t\t\t0.08\n",
      "B25_EYESC:\t\t\t0.07\n",
      "B28_EYESC:\t\t\t0.05\n",
      "B17_EYESC:\t\t\t0.03\n",
      "B31_EYESC:\t\t\t0.03\n",
      "A32_EYESO:\t\t\t0.03\n",
      "B12_EYESC:\t\t\t0.02\n",
      "B22_EYESC:\t\t\t0.02\n",
      "B25_EYESO:\t\t\t0.02\n",
      "A28_EYESO:\t\t\t0.02\n",
      "A25_EYESC:\t\t\t0.01\n",
      "AVG_PSD_EYESO:\t\t\t0.01\n",
      "A01_EYESC:\t\t\t0.01\n",
      "B32_EYESO:\t\t\t0.01\n",
      "A20_EYESC:\t\t\t0.00\n",
      "A13_EYESO:\t\t\t0.00\n",
      "B22_EYESO:\t\t\t0.00\n",
      "A20_EYESO:\t\t\t0.00\n",
      "RTEMPORAL_EYESC:\t\t\t0.00\n",
      "B30_EYESC:\t\t\t0.00\n",
      "B12_EYESO:\t\t\t0.00\n",
      "A10_EYESC:\t\t\t0.00\n",
      "B26_EYESC:\t\t\t0.00\n"
     ]
    }
   ],
   "source": [
    "import warnings                 # sklearn is using a deprecated rand function here,\n",
    "with warnings.catch_warnings(): # and warnings clutter output\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    resamplings = 2000\n",
    "    rlogit = linear_model.RandomizedLogisticRegression(n_resampling=resamplings)\n",
    "    rlogit.fit(X, y)\n",
    "    print(\"Features sorted by score, using {} resamplings: \".format(resamplings))\n",
    "    feature_list = sorted(zip(map(lambda x: round(x, 4), rlogit.scores_), cols), reverse=True)\n",
    "    for f in feature_list[0:25]: # Adjust this if last feature output is nonzero\n",
    "        print(\"{}:\\t\\t\\t{:.2f}\".format(f[1], f[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entire dataset, LASSO for age as interest variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by score, using 2000 resamplings: \n",
      "A32_EYESC:\t\t\t0.45\n",
      "B32_EYESC:\t\t\t0.29\n",
      "B25_EYESO:\t\t\t0.24\n",
      "A28_EYESO:\t\t\t0.23\n",
      "B25_EYESC:\t\t\t0.17\n",
      "B17_EYESC:\t\t\t0.08\n",
      "A28_EYESC:\t\t\t0.06\n",
      "B32_EYESO:\t\t\t0.03\n",
      "B17_EYESO:\t\t\t0.03\n",
      "AVG_PSD_EYESO:\t\t\t0.03\n",
      "A32_EYESO:\t\t\t0.02\n",
      "A21_EYESO:\t\t\t0.02\n",
      "A27_EYESC:\t\t\t0.01\n",
      "B15_EYESC:\t\t\t0.01\n",
      "A20_EYESO:\t\t\t0.01\n",
      "A20_EYESC:\t\t\t0.01\n",
      "B01_EYESO:\t\t\t0.01\n",
      "A10_EYESC:\t\t\t0.01\n",
      "RTEMPORAL_EYESO:\t\t\t0.01\n",
      "B02_EYESO:\t\t\t0.01\n",
      "RTEMPORAL_EYESC:\t\t\t0.01\n",
      "A01_EYESC:\t\t\t0.01\n",
      "B31_EYESC:\t\t\t0.01\n",
      "B22_EYESC:\t\t\t0.00\n",
      "B30_EYESC:\t\t\t0.00\n",
      "B16_EYESO:\t\t\t0.00\n",
      "A16_EYESC:\t\t\t0.00\n",
      "B19_EYESC:\t\t\t0.00\n",
      "B09_EYESO:\t\t\t0.00\n",
      "A08_EYESO:\t\t\t0.00\n",
      "LTEMPORAL_EYESC:\t\t\t0.00\n",
      "B28_EYESC:\t\t\t0.00\n",
      "B16_EYESC:\t\t\t0.00\n",
      "B03_EYESO:\t\t\t0.00\n",
      "A12_EYESO:\t\t\t0.00\n",
      "B24_EYESC:\t\t\t0.00\n",
      "A23_EYESC:\t\t\t0.00\n",
      "A16_EYESO:\t\t\t0.00\n",
      "LTEMPORAL_EYESO:\t\t\t0.00\n",
      "FRONTAL_EYESO:\t\t\t0.00\n",
      "B31_EYESO:\t\t\t0.00\n",
      "B24_EYESO:\t\t\t0.00\n",
      "B22_EYESO:\t\t\t0.00\n",
      "B15_EYESO:\t\t\t0.00\n",
      "B11_EYESC:\t\t\t0.00\n",
      "B09_EYESC:\t\t\t0.00\n",
      "B07_EYESC:\t\t\t0.00\n",
      "A25_EYESC:\t\t\t0.00\n",
      "A24_EYESO:\t\t\t0.00\n",
      "A22_EYESO:\t\t\t0.00\n"
     ]
    }
   ],
   "source": [
    "X, y = df[cols], df.AGE\n",
    "\n",
    "import warnings                 # sklearn is using a deprecated rand function here,\n",
    "with warnings.catch_warnings(): # and warnings clutter output\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    resamplings = 2000\n",
    "    rlasso = linear_model.RandomizedLasso(n_resampling=resamplings)\n",
    "    rlasso.fit(X, y)\n",
    "    print(\"Features sorted by score, using {} resamplings: \".format(resamplings))\n",
    "    feature_list = sorted(zip(map(lambda x: round(x, 4), rlasso.scores_), cols), reverse=True)\n",
    "    for f in feature_list[0:50]: # Adjust this if last feature output is nonzero\n",
    "        print(\"{}:\\t\\t\\t{:.2f}\".format(f[1], f[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
